% This is LLNCS.DEM the demonstration file of
% the LaTeX macro package from Springer-Verlag
% for Lecture Notes in Computer Science,
% version 2.4 for LaTeX2e as of 16. April 2010
%
\documentclass{llncs}
%
\usepackage{makeidx}  % allows for indexgeneration
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{tikz}

\makeatletter

\newcommand*\circled[1]{\tikz[baseline=(char.base)]{
            \node[shape=circle,draw,inner sep=2pt] (char) {#1};}}


\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
  \hskip -\arraycolsep
  \let\@ifnextchar\new@ifnextchar
  \array{#1}}
\makeatother

%
\begin{document}
\pagestyle{plain}
%
\frontmatter          % for the preliminaries
%
\pagestyle{headings}  % switches on printing of running heads
\author{Drago\c{s} Alin Rotaru}
\institute{University of Bristol}
%
\title{Solving LP problems}
%
\titlerunning{Simplex Algorithm}  % abbreviated title (for running head)
%                                     also used for the TOC unless
%                                     \toctitle is used
%
\maketitle              % typeset the title of the contribution



\section{Diet problem}

The diet problem is a classical application for describing a standard minimum problem in linear programming.

There are $m$ types of food $F_1, \dots, F_m$ and $n$ types of nutrients $N_1, \dots, N_n$. Let $b_i$ be the price of food $F_i$ per unit and $c_j$ the minimal requirement for nutrient $N_j$. We are also given a matrix $a_{ij}$ which maps the quantity of nutrient $N_j$ in food type $F_i$.

Our goal is to find $y_1,\dots,y_m$ such that $\sum\limits_{i=1}^m y_ib_i$ subject to $y \geq 0$ and $\sum\limits_{i=1}^m{y_i a_{ji}} \geq c_j$ for every $j \in {1,\dots,n}$.


% Food matching
\section{Formalised versions of LP problems}

\subsection{Standard maximum problem}

Given a matrix $A \in \mathbb{R}^{m \times n}$, a vector $b \in \mathbb{R}^m$ and a vector $c \in \mathbb{R}^n$. Find a vector $x \in \mathbb{R}^n$ such that $c^.Tx$ is maximum subject to: $Ax \geq b$, $x \geq 0$.

%$ A = \begin{bmatrix} a_{11} & \cdots & a_{1n} \\ \vdots & \ddots & \vdots \\ a_{m1} & \cdots & a_{mn} \end{bmatrix}- $
\subsection{Standard minimum problem}

Given a matrix $A \in \mathbb{R}^{m \times n}$, a vector $b \in \mathbb{R}^m$ and a vector $c \in \mathbb{R}^n$. Find a vector $y \in \mathbb{R}^m$ such that $y^Tb$ is minimum subject to: $y^TA \geq c^T$, $y \geq 0$.

\section{Duality theorem}

The two problems from above are dual to each other and they are connected through the following result:

\begin{theorem}
	If a standard LP program has a bounded feasible solution then it's optimal feasible solution is equal to the optimal feasible solution of it's dual LP.
\end{theorem}

Pretty neat. We can use this theorem (among other things) to check our candidate solution for a standard problem is optimal by testing it through the dual. This is due to the following result:

\begin{theorem}
	Let $x^*$ be a feasible solution for the standard maximum LP problem and $y^*$ be a feasible solution for it's dual.
	$x^*$ and $y^*$ are optimal feasible iff:

	\begin{itemize}
		\item $x_j^* = 0$ for all $j$ which $\sum\limits_{i=1}^m a_{ij}y_i^* > c_j$
		\item $y_i^* = 0$ for all $i$ which $\sum\limits_{j=1}^n a_{ij}x_j^* < b_i$
	\end{itemize}
\end{theorem}


\begin{proof}

Let's prove the only if part:

Following from the first and the the second equation we rewrite $\sum\limits_{i=1}^m y_i^*b_i$ as $\sum\limits_{i=1}^m y_i^*$
$ \sum\limits_{j=1}^n a_{ij}x_j^* =  \sum\limits_{i=1}^m \sum\limits_{j=1}^m a_{ij}y_i^*x_j^* = \sum\limits_{j=1}^n c_jx_j^*$.

\end{proof}


\section{How to pivot?}
Assume we have a system of equations:

\[  % no need to use "align*" env.
\setlength\arraycolsep{1.5pt} % default value: 5pt
\left\{
\begin{array}{ccc ccc ccc c @{\extracolsep{2.5pt}}c@{\extracolsep{2.5pt}}c}
a_{1,1}x_{1} & + & \cdots & + & a_{1,j}x_{j} & + & \cdots & + & a_{1,n}x_{n} & = & -y_{1} \\

\vdots & & \vdots & & \ddots & &  \vdots & &  \vdots \\
a_{i,1}x_{1} & + & \cdots & + & a_{i,j}x_{j} & + & \cdots & + & a_{i,n}x_{n} & = & -y_{i} \\
\vdots & & \vdots & & \ddots & &  \vdots & &  \vdots \\
a_{m,1}x_{1} & + & \cdots & + & a_{m,j}x_{j} & + & \cdots & + & a_{m,n}x_{n} & = & -y_{m} \\
\end{array}
\right.
\]

Sometimes it's useful to express the system in terms of different variables, say expressing $-x_{j}$ in terms of $y_{i}$. The $i$'th equation becomes:
\begin{equation}
   \frac{a_{i,1}}{a_{i,j}}x_1 + \cdots +\frac{a_{i,j-1}}{a_{ij}} x_{j-1} + \frac{1}{a_{ij}}y_i +\frac{a_{i,j+1}}{a_{ij}}x_{j+1} + \cdots +\frac{a_{i,n}}{a_{i,j}}x_n = -x_j
\end{equation}

The other equations become:

\begin{align*}
  (a_{k,1} - \frac{a_{i,1}a_{k,j}}{a_{i,j}}) x_1 + \cdots + (a_{k,j-1} - \frac{a_{i,j-1}a_{k,j}}{a_{i,j}})x_{j-1} - \frac{a_{k,j}}{a_{i,j}}y_i + \cdots \\
  + (a_{k,n} - \frac{a_{i,n}a_{k,j}}{a_{i,j}})x_n = 
  -y_k 
\end{align*}

After pivoting the coefficients matrix change and we can incorporate this into the following rule:
\begin{align}
\begin{bmatrix}
  p & q \\
  r & s \\
\end{bmatrix}
& \rightarrow
\begin{bmatrix}
  \frac{1}{p} & & \frac{q}{p} \\
  -\frac{r}{p} & & s-\frac{qr}{p} \\
\end{bmatrix}
\end{align}

We notice that this rule is similar to the gaussian elimination - but not the same!

\begin{align}
\begin{bmatrix}
  p & q \\
  r & s \\
\end{bmatrix}
& \rightarrow
\begin{bmatrix}
  \frac{1}{p} & & \frac{q}{p} \\
  0 & & s-\frac{qr}{p} \\
\end{bmatrix}
\end{align}


\section{Solving the maximum standard problem with the simplex tableau}


\subsection{Simplex tableau}

One may wonder why did we choose to put the $y_i$ variables with a minus sign. The answer is that if we add a slack variable $u = b - Ax$ this renders $-u = Ax - b$.

The original problem now becomes:

\begin{align*}
\text{max}(c^Tx) \text{  subject to} \\
u \geq 0 \text{ and } x \geq 0
\end{align*}



This can be written in a more canonical form - also called the simplex tableau.

\begin{equation}
\begin{array}{c|cccc|cc}
  {} & x_1 & x_2 & \cdots & x_n & b \\ \hline
  -u_1 & a_{1,1} & a_{1,2} & \cdots & a_{1,n} & b_1 \\
  -u_2 & a_{2,1} & a_{2,2} & \cdots & a_{2,n} & b_2  \\
  \vdots  &  \vdots  & \vdots & \vdots & \vdots & \vdots \\
  -u_m & a_{m,1} & a_{m,2} & \cdots & a_{m,n} & b_m \\ \hline
  c & -c_1    & -c_2    & \cdots & -c_n    &  0 \\
\end{array}
\end{equation}


When $b \geq 0$ and $-c \geq 0$ then we have an obvious solution $x = 0$. Computing $c^Tx$ when $-c \geq 0$ reaches it's maximum value when $x = 0$.
Though in some cases we might not be that lucky, so we have to pivot.

We claim that the bottom right value is actually the value of the objective function.

Choose a value $a_{i,j} \neq 0$ and pivot around it. For example, if $a_{1,2} \neq 0$. The simplex tableau becomes:



\begin{equation}
\begin{array}{c|cccc|cc}
  {} & x_1 & u_1 & \cdots & x_n & b \\ \hline
  -x_2 & \tilde{a}_{1,1} & \tilde{a}_{1,2} & \cdots & \tilde{a}_{1,n} & \tilde{b}_1 \\
  -u_2 & \tilde{a}_{2,1} & \tilde{a}_{2,2} & \cdots & \tilde{a}_{2,n} & \tilde{b}_2  \\
  \vdots  &  \vdots  & \vdots & \vdots & \vdots & \vdots \\
  -u_m & \tilde{a}_{m,1} & \tilde{a}_{m,2} & \cdots & \tilde{a}_{m,n} & \tilde{b}_m \\ \hline
  c & -\tilde{c}_1    & -\tilde{c}_2    & \cdots & -\tilde{c}_n    &  \tilde{v} \\
\end{array}
\end{equation}

The objective function $c^Tx$ is:
\begin{multline}
  \sum\limits_{j=1}^n c_jx_j = c_1 x_1 + c_2\frac{1}{a_{1,2}} \Big(- x_1 a_{1,1} - u_1 - \cdots - x_n a_{1,n} + b_1\Big) + c_3x_3 + \cdots + c_nx_n = \\
  x_1\Big(c_1 - \frac{a_{1,1}c_2}{a_{1,2}}\Big) + u_1 \Big( -\frac{c_2}{a_{1,2}} \Big) + \cdots + x_n\Big(c_n - \frac{a_{1,n}c_2}{a_{1,2}}\Big) + \frac{b_1c_2}{a_{1,2}}
\end{multline}


Which is exactly what we want! In the simplex tableau we have $-\tilde{c}_i$ such that when summing $-\tilde{c}_1 x_1 - \tilde{c}_2 u_1 - \dots \tilde{c}_n x_n$ this yields the value of the objective function.

This says that the pivoting rules can be applied on the entire table, except to the leftmost column and the top one.

\subsection{How to choose pivots?}
\label{subsec:pivoting}

The purpose is to make the bottom row and the rightmost column (without the corners) containing only positive numbers. If that's the case the solution is built by setting the $x_j$'s on top to $0$ and the $x_i$'s on the left eqaul to $b_i$'s on the right.


\subsubsection{Case 1. $\tilde{b} \geq 0$}
\label{subsub:case-1}

  Some $-c_j < 0$. Pick one $j0$ such that $-\tilde{c_{j0}} < 0$. From all positive $a_{i,j0} > 0$ pivot around $a_{i0,j0}$ such that $b_i/a_{i0,j0}$ is minimum. If there aren't any positive $a_{i0,j0}$ then the solution is unbounded feasible - every solution work.

  If there aren't any $-\tilde{c_j} \geq 0$ then we are done - beginning of \ref{subsec:pivoting}.

\subsubsection{Case 2. Some $\tilde{b_i} < 0$}
  Choose any $i0$ such that $\tilde{b_i0} < 0$. From all negative values $a_{i0, j} < 0$ pivot around $a_{i0, j0}$ such that $b_{i0}/a_{i0, j0}$ is minimum. If there aren't any negative $a_{i0, j0}$ then the solution is infeasible.

  If there aren't any $-\tilde{b_i0} < 0$ then we go to the previous case.


\subsubsection{Proofs}
Pivoting this way works because at each step the value of the bottom row or rightmost column increases with some non-negative quantity. TODO

Let's take a problem left as an exercise from \cite{ferguson2000linear}

\begin{example}
  Maximize $3x_1 + 4x_2 + 5x_3$ subject to $x_j \geq 0$ for all $j$ and
\begin{equation}
\begin{array}{cccccc}
   x_1 & + & 2x_2 + & 2x_3 & \leq & 1 \\
  -3x_1 & + & {} & x_3 & \leq & -1 \\
  -2x_1 & - & x_2 & {} & \leq & -1 \\
\end{array} 
\end{equation}

As a first step we write the simplex tableau of this expression.

\begin{equation}
\begin{array}{c|ccc|cc}
  {} & x_1    & x_2 & x_3 & b \\ \hline
  -u_1 & 1    & 2 & 2 & 1 \\
  -u_2 & \circled{-3}   & 0 & 1 & -1  \\
  -u_3 & -2   & -1 & 0 & -1 \\ \hline
  c    & -3 & -4 & -5    &  0 \\
\end{array}
\end{equation}

Choose the $-1$ on the second row. Pivot around $a_{2,1}$ because the quotient $b_2 / a_{2, i}$ is minimum.

The simplex tableau now becomes:

\begin{equation}
\begin{array}{c|ccc|cc}
  {} & u_2   & x_2 & x_3 & b \\ \hline
  -u_1 & 1/3 & 2 & 7/3 & 2/3 \\
  -x_1 & -1/3 & 0 & -1/3 & 1/3  \\
  -u_3 & -2/3 & \circled{-1} & -2/3 & -1/3 \\ \hline
  c    & -1/1 & -4 & -6 & 1 \\
\end{array}
\end{equation}

There is a negative cell in the last column and apply again the case $2$ rule by fixing the pivot in $a_{3,2}$.

\begin{equation}
\begin{array}{c|ccc|cc}
  {} & u_2    & u_3 & x_3 & b \\ \hline
  -u_1 & -1 & \circled{2} & 1 & 0  \\
  -x_1 & -1/3 & 0 & -1/3 & 1/3 \\
  -x_2 & 2/3 & -1 & 2/3 & 1/3 \\ \hline
  c    & 5/3 & -4 & -10/3 & 7/3 \\
\end{array}
\end{equation}

Pivot around $a_{1,2}$

\begin{equation}
\begin{array}{c|ccc|cc}
  {} & u_2    & u_1 & x_3 & b \\ \hline
  -u_3 & -1/2 & 1/2 & 1/2 & 0   \\
  -x_1 & -1/3 & 0 & -1/3 & 1/3  \\
  -x_2 & \circled{1/6} & 1/2 & 7/6 & 1/3 \\ \hline
  c    & -1/3 & 2 & -4/3 & 7/3 \\
\end{array}
\end{equation}


After pivoting at $a_{3,1}$, the simplex tableau becomes:

\begin{equation}
\begin{array}{c|ccc|cc}
  {} & x_2    & u_1 & x_3 & b \\ \hline
  -u_2 &  3 & 2 & 4 & 1   \\
  -x_1 & 2 & 1 & 2 & 1  \\
  -u_2 & 6 & 3 & 7 & 2 \\ \hline
  c    & 2 & 3 & 1 & 3 \\
\end{array}
\end{equation}

In the bottom right corner we find the value of the objective function is $3$. The optimal feasible solution is $x_1 = 1, x_2 = 0, x_3 = 0$.

\end{example}


\section{Solve general problems using Simplex Method}

Simplex tableau method can also be used to solve more general systems - unconstrained variables and additional given equalities. The solution is to add more variables such that the new system looks like a classical one and pivot on their coefficients first.

\section{Different approaches to solving LP problems}

Cris Cross algorithm which has polynomial time but performs worse on the average case compared with the simplex. Didn't managed to study this.

% ---- Bibliography ----
%

\clearpage
\bibliographystyle{splncs03}
\bibliography{llncs}
\end{document}
